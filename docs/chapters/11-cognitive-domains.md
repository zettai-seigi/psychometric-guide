---
layout: default
title: "Chapter 11: Cognitive Domains and the g Factor"
parent: "Part III: Verify Ability Tests"
nav_order: 2
---

# Chapter 11: Cognitive Domains and the g Factor
{: .no_toc }

## Table of Contents
{: .no_toc .text-delta }

1. TOC
{:toc}

---

## Learning Objectives

By the end of this chapter, you will be able to:

1. Explain Carroll's three-stratum theory as the foundation for cognitive ability measurement
2. Describe the hierarchical structure of intelligence from narrow abilities to the g factor
3. Understand why General Mental Ability (g) predicts job performance so consistently
4. Identify the cognitive processes underlying each Verify reasoning domain
5. Recognize how Numerical Reasoning manifests in workplace tasks
6. Explain the True/False/Cannot Say logic of Verbal Reasoning assessment
7. Understand Inductive Reasoning as a measure of fluid intelligence and novel problem-solving
8. Grasp how the three domains relate to each other and to general mental ability

---

## Introduction: The Architecture of Intelligence

How should we conceptualize human intelligence? Is it a single, unified capacity, or a collection of independent abilities? This question has occupied psychologists for over a century, and the answer has profound implications for how we measure cognitive ability in organizational settings.

The modern consensus, built on decades of factor-analytic research, is that **intelligence is hierarchical**. We possess both general mental ability—the capacity that underlies performance across diverse cognitive tasks—and more specific abilities that apply within particular domains. This hierarchical structure provides the theoretical foundation for the Verify suite's three-domain architecture.

This chapter explores the psychometric models that describe the structure of intelligence, with particular emphasis on Carroll's three-stratum theory. We then examine each of the three reasoning domains measured by Verify—Numerical, Verbal, and Inductive—exploring the cognitive processes they engage and their relevance to workplace performance.

Understanding this theoretical architecture is not merely academic. It informs critical decisions: When should organizations use a broad GMA measure versus domain-specific tests? How should we interpret score profiles? What does a candidate's pattern of strengths and weaknesses reveal about their likely job performance? These practical questions depend on grasping the structure of human cognitive abilities.

---

## Hierarchical Models of Intelligence: From Spearman to Carroll

### Spearman's g Factor: The Beginning

The story begins with Charles Spearman's 1904 observation of a curious statistical pattern: when people take multiple cognitive tests, their scores correlate positively. Those who perform well on verbal tasks tend to perform well on mathematical tasks, spatial tasks, and so on. Spearman used factor analysis to explain this pattern, proposing that a single underlying factor—**general intelligence or g**—accounts for the common variance across diverse cognitive measures.

Spearman's model was elegant but incomplete. While g explained the correlations between tests, it didn't account for all the variance. Some tests correlated more strongly with each other than g alone would predict, suggesting the existence of more specific factors. This observation led subsequent researchers to propose multifactor models.

### Thurstone's Primary Mental Abilities

Louis Thurstone challenged Spearman's emphasis on g, proposing instead that intelligence comprises several independent **Primary Mental Abilities**:

- **Verbal Comprehension:** Understanding and using language
- **Word Fluency:** Producing words rapidly
- **Number Facility:** Performing arithmetic operations
- **Spatial Visualization:** Manipulating mental images
- **Associative Memory:** Remembering paired information
- **Perceptual Speed:** Identifying visual patterns quickly
- **Reasoning:** Solving novel problems

Thurstone's model provided a richer description of cognitive diversity but raised a new puzzle: these "independent" factors still correlated with each other. This suggested that g hadn't been eliminated—merely pushed to a higher level of abstraction.

### Cattell and Horn: Fluid and Crystallized Intelligence

Raymond Cattell and John Horn refined the hierarchical perspective by proposing two broad types of intelligence:

**Fluid Intelligence (Gf):**
- The capacity to solve novel problems
- Independent of acquired knowledge
- Peaks in early adulthood and gradually declines
- Assessed through abstract reasoning and pattern recognition tasks

**Crystallized Intelligence (Gc):**
- Accumulated knowledge and skills
- Dependent on education and cultural exposure
- Continues to grow throughout adulthood
- Assessed through vocabulary, general information, and verbal comprehension

This Gf-Gc model acknowledged both general and specific factors while providing a developmentally meaningful framework. It explained why some abilities (fluid) decline with age while others (crystallized) are maintained or even improve.

### Carroll's Three-Stratum Theory: The Definitive Synthesis

John B. Carroll's monumental 1993 work, *Human Cognitive Abilities*, synthesized over 460 factor-analytic studies to propose a comprehensive hierarchical model. **Carroll's three-stratum theory** remains the dominant framework for understanding intelligence structure.

**Stratum III (Top): General Intelligence (g)**
At the apex sits g, the most general factor accounting for variance common to all cognitive tasks. This is the psychological construct most relevant to predicting learning, job performance, and life outcomes. It reflects the efficiency of fundamental information-processing mechanisms.

**Stratum II (Middle): Broad Abilities**
Eight broad factors sit beneath g, including:
- **Fluid Intelligence (Gf):** Novel problem-solving, inductive and deductive reasoning
- **Crystallized Intelligence (Gc):** Verbal comprehension, language-based knowledge
- **General Memory and Learning (Gy):** Encoding, storing, and retrieving information
- **Visual Perception (Gv):** Spatial reasoning and mental imagery
- **Auditory Perception (Gu):** Processing and discriminating sounds
- **Processing Speed (Gs):** Speed of executing cognitive operations
- **Reaction Time/Decision Speed (Gt):** Speed of simple reactions
- **Quantitative Knowledge (Gq):** Mathematical and numerical facility

**Stratum III (Bottom): Narrow Abilities**
At the base of the hierarchy lie approximately 70 narrow abilities—specific cognitive skills like reading comprehension, mathematical reasoning, spatial relations, perceptual speed, and associative memory. These are the most specific level of cognitive function.

### The Hierarchical Relationship

The three strata are not independent layers but represent different levels of abstraction. Performance on any cognitive task is influenced by:

1. The **narrow ability** most directly relevant to the task
2. The **broad ability** under which that narrow ability clusters
3. The **general ability (g)** that pervades all cognitive performance

This hierarchical structure explains both the unity and diversity of intelligence. All cognitive abilities share common variance (explained by g), but they also exhibit domain-specific variance (explained by broad and narrow factors).

---

## The g Factor: General Mental Ability in the Workplace

### What Is g?

At the most fundamental level, g reflects **individual differences in the efficiency of information processing**. While researchers debate its neurological basis, converging evidence suggests g is related to:

- **Working memory capacity:** The ability to hold and manipulate information temporarily
- **Processing speed:** The rate at which cognitive operations are executed
- **Neural efficiency:** More efficient brains consume less glucose during cognitive tasks
- **Executive function:** The capacity to control attention, inhibit impulses, and coordinate multiple processes

These mechanisms underlie performance across all cognitive domains. A person with high working memory capacity will excel at holding multiple pieces of information simultaneously—whether those pieces are numbers from a table, facts from a business report, or patterns in a visual array.

### Why g Predicts Job Performance

The robust relationship between General Mental Ability and job performance—one of the most replicated findings in industrial-organizational psychology—stems from several mechanisms:

**1. Learning and Training**
Jobs require acquiring knowledge and skills. Higher g enables faster learning, reducing training time and allowing employees to reach proficiency more quickly. This advantage compounds over time as employees continuously adapt to new technologies, processes, and responsibilities.

**2. Problem-Solving and Decision-Making**
Most jobs involve solving problems under uncertainty: diagnosing equipment failures, resolving customer complaints, optimizing processes, allocating resources. These tasks require recognizing patterns, generating solutions, evaluating alternatives, and making sound judgments—all cognitive processes influenced by g.

**3. Complexity and Cognitive Demand**
As jobs become more complex—involving more variables, less routine, greater ambiguity—the correlation between g and performance strengthens. Meta-analyses show that for highly complex jobs, the validity coefficient can exceed 0.50, making GMA one of the strongest single predictors available.

**4. Adaptability and Transfer**
The modern workplace demands flexibility. Employees must master new software, adapt to organizational changes, and transfer learning across contexts. Higher g facilitates this adaptability because it represents the capacity to handle novelty and extract underlying principles that apply across situations.

**5. Information Processing Demands**
Knowledge work increasingly involves processing information: reading reports, analyzing data, synthesizing insights, communicating findings. All these activities tax the information-processing mechanisms reflected in g.

### Meta-Analytic Evidence

Decades of validation research support g's predictive power:

- **Hunter and Hunter (1984):** Across all jobs, GMA shows an average validity of 0.51 for predicting job performance and 0.56 for predicting training success
- **Schmidt and Hunter (1998):** GMA is the best single predictor of job performance across occupations, with validities ranging from 0.23 (unskilled jobs) to 0.58 (professional/managerial jobs)
- **Ones, Dilchert, and Viswesvaran (2010):** Updated meta-analyses confirm GMA's status as the most valid single predictor

These validities are remarkable because they:
- Apply across virtually all occupations (though strength varies by complexity)
- Are robust across cultures and contexts
- Show little deterioration over time
- Generalize across performance criteria (quality, quantity, training, advancement)

### The Practical Implication

For organizational selection, GMA testing provides a highly efficient method for predicting who will succeed. While other factors matter—personality, motivation, specific skills—cognitive ability sets the upper bound on how complex a job an individual can master and how quickly they can learn what they need to know.

---

## Numerical Reasoning: Quantitative Intelligence at Work

### Defining Numerical Reasoning

**Numerical Reasoning** assesses the capacity to interpret, manipulate, and draw logical conclusions from quantitative information. It is not merely arithmetic computation—calculators can handle that—but rather the ability to **extract meaning from numbers** and **reason logically about quantitative relationships**.

In Carroll's three-stratum framework, Numerical Reasoning draws primarily on:
- **Quantitative Knowledge (Gq):** The broad ability to understand and manipulate mathematical concepts
- **Fluid Intelligence (Gf):** The capacity to reason logically about novel quantitative problems
- **General Intelligence (g):** The overall information-processing efficiency that supports all reasoning

### Cognitive Processes in Numerical Reasoning

When a candidate analyzes a business chart or interprets a data table, multiple cognitive processes operate simultaneously:

**1. Visual-Spatial Processing**
Reading graphs and tables requires mapping visual elements (bars, lines, pie segments) onto quantitative values. The candidate must understand the axes, identify the relevant data series, and extract specific values—a task requiring coordination between visual perception and numerical understanding.

**2. Working Memory**
Most numerical reasoning items require holding multiple values in mind simultaneously. To calculate "What percentage increase in revenue did Region A experience from Q1 to Q4?" the candidate must:
- Extract the Q1 value
- Extract the Q4 value
- Hold both in working memory
- Calculate the difference
- Calculate the percentage
- Compare to response options

Working memory capacity—a core component of g—directly determines how many values can be juggled without error.

**3. Quantitative Reasoning**
Understanding relationships between numbers goes beyond calculation. It involves recognizing:
- Proportional relationships (if X doubles, Y halves)
- Trends and patterns (steady growth vs. exponential acceleration)
- Comparative magnitudes (which is larger? by how much?)
- Logical implications (if sales increased but profit decreased, costs must have risen)

**4. Logical Inference**
Many numerical items require drawing conclusions beyond what's explicitly stated:
- "If the trend continues, what will happen next year?" (extrapolation)
- "Which region has the highest growth rate?" (requires calculating rates for comparison)
- "Could the total expenses exceed revenue?" (requires considering ranges and uncertainties)

**5. Attention and Precision**
A single misread value or arithmetic error produces an incorrect answer. Numerical reasoning thus requires sustained attention, careful checking, and tolerance for detail-oriented work.

### Typical Verify Numerical Reasoning Items

**Chart Interpretation:**
A bar chart shows quarterly sales for four regions. Questions ask candidates to:
- Identify which region had highest Q3 sales
- Calculate the percentage increase for Region B from Q2 to Q4
- Determine which region showed the greatest percentage growth
- Evaluate whether a statement about trends is true, false, or cannot be determined

**Table Analysis:**
A table presents financial data for five product lines (revenue, costs, profit margin). Questions require:
- Calculating derived values (total profit = revenue × margin)
- Making comparisons (which product is most profitable?)
- Identifying trends (which product's margin is improving?)
- Drawing inferences (if costs increase 10%, which product line would become unprofitable?)

**Data Integration:**
Multiple charts or tables present related information. Candidates must:
- Combine information from multiple sources
- Recognize when data is insufficient to answer a question
- Identify contradictions or inconsistencies
- Make multi-step inferences

### Workplace Relevance

Numerical reasoning predicts performance in roles requiring:

**Financial Analysis:**
Budgeting, forecasting, financial modeling, and variance analysis all demand the ability to interpret quantitative data and draw sound conclusions.

**Data-Driven Decision-Making:**
Modern managers receive dashboards, reports, and analytics. Those with strong numerical reasoning can extract insights and make evidence-based decisions rather than relying on intuition alone.

**Quality Control and Process Optimization:**
Identifying trends in defect rates, analyzing process metrics, and troubleshooting quality issues require quantitative reasoning.

**Strategic Planning:**
Evaluating market data, assessing competitive positions, and forecasting scenarios involve sophisticated numerical reasoning.

**Research and Analysis:**
Scientists, analysts, and researchers must interpret experimental data, statistical results, and technical specifications.

In an increasingly data-driven economy, numerical reasoning is no longer limited to quantitative specialists—it has become a core competency across job families and levels.

---

## Verbal Reasoning: Logic and Language in Professional Contexts

### Defining Verbal Reasoning

**Verbal Reasoning** measures the ability to **evaluate logical arguments, assess evidence, and draw sound conclusions from written information**. Unlike reading comprehension (which assesses understanding of text) or vocabulary (which measures word knowledge), verbal reasoning focuses on **logical thinking applied to verbal material**.

In Carroll's framework, Verbal Reasoning draws on:
- **Crystallized Intelligence (Gc):** Verbal comprehension and language facility
- **Fluid Intelligence (Gf):** Deductive reasoning and logical inference
- **General Intelligence (g):** The capacity to process information and reason systematically

### The True/False/Cannot Say Format

Verify Verbal Reasoning typically uses the classic **deductive reasoning format**:

1. **Candidate reads a passage** (typically 50-150 words describing a business situation, policy, or scenario)
2. **Candidate evaluates a statement** about the passage
3. **Candidate selects one of three options:**
   - **True:** The statement logically follows from the passage
   - **False:** The statement contradicts the passage or is logically inconsistent with it
   - **Cannot Say:** Insufficient information is provided to determine truth or falsity

This format assesses **deductive logic**—the ability to determine what must be true, what must be false, and what remains uncertain given a set of premises.

### The Logic of "Cannot Say"

The "Cannot Say" option is psychologically challenging because it requires distinguishing **logical entailment** from **probable inference**. Consider:

**Passage:** "Companies that invest heavily in employee training typically experience lower turnover rates. TechCorp has recently doubled its training budget."

**Statement:** "TechCorp will experience reduced turnover."

**Correct Answer:** Cannot Say

**Explanation:** While the passage suggests a general relationship between training and turnover, it does not assert that this relationship holds in every case. TechCorp's increased training *might* reduce turnover, but other factors could intervene. The statement is plausible but not logically entailed by the passage.

Many candidates struggle with "Cannot Say" because:
- Real-world thinking encourages probable inference (it *seems* likely TechCorp's turnover will decrease)
- The format requires suppressing background knowledge and common sense
- Distinguishing "probably true" from "definitely true" demands metacognitive monitoring

This is precisely what makes verbal reasoning a strong predictor of job performance: it measures the capacity for **disciplined logical thinking** even when intuitions suggest otherwise.

### Cognitive Processes in Verbal Reasoning

**1. Reading Comprehension**
Before reasoning can begin, candidates must accurately understand the passage. This involves:
- Parsing sentence structure
- Understanding vocabulary and terminology
- Identifying key facts and relationships
- Constructing a mental model of the situation

**2. Deductive Logic**
The core process is applying logical rules:
- **Modus Ponens:** If P implies Q, and P is true, then Q must be true
- **Modus Tollens:** If P implies Q, and Q is false, then P must be false
- **Transitive Inference:** If A > B and B > C, then A > C
- **Logical Negation:** Understanding what it means to contradict a statement

**3. Information Integration**
Many items require combining multiple facts from the passage:
- "All managers have access to the database. Sarah is a manager. Therefore, Sarah has access to the database." (requires linking two premises)

**4. Distinguishing Fact from Inference**
Strong verbal reasoners distinguish:
- What the passage explicitly states
- What logically follows from stated facts
- What is suggested but not proven
- What contradicts stated facts

**5. Working Memory and Attention**
Longer passages require holding multiple facts in mind while evaluating their logical relationships. This taxes working memory, a core component of g.

### Typical Verify Verbal Reasoning Items

**Policy Interpretation:**
A passage describes company policy regarding vacation accrual. Questions assess whether candidates can correctly determine:
- Who is eligible for a benefit
- Under what conditions a policy applies
- What happens in edge cases not explicitly addressed

**Logical Arguments:**
A passage presents an argument or causal claim. Questions assess:
- Whether a conclusion follows logically
- Whether evidence supports a claim
- Whether a counter-example invalidates reasoning

**Business Scenarios:**
A passage describes a business situation (market conditions, organizational changes, strategic decisions). Questions require:
- Drawing inferences about causes and effects
- Evaluating whether statements about the situation are justified
- Identifying what can versus cannot be determined from available information

### Workplace Relevance

Verbal reasoning predicts performance in roles requiring:

**Document Analysis:**
Legal contracts, policy documents, regulatory requirements, and technical specifications all demand careful logical analysis of written material.

**Critical Thinking:**
Managers must evaluate arguments, assess evidence quality, distinguish sound reasoning from fallacies, and make decisions based on rigorous analysis.

**Strategic Planning:**
Developing strategies requires understanding complex situations described in written reports, identifying logical implications, and forecasting consequences.

**Communication:**
Strong verbal reasoners produce clearer writing because they understand logical structure, recognize ambiguity, and express ideas precisely.

**Problem Diagnosis:**
Troubleshooting often involves analyzing written reports of symptoms, evaluating possible causes, and reasoning systematically about relationships.

In professional contexts, the ability to think clearly about verbally presented information is essential. Verbal reasoning separates those who can perform sophisticated cognitive work from those who will struggle with the logical demands of managerial and professional roles.

---

## Inductive Reasoning: Fluid Intelligence and Novel Problem-Solving

### Defining Inductive Reasoning

**Inductive Reasoning**, also called Diagrammatic Reasoning or Abstract Reasoning, assesses the capacity to **identify patterns, infer rules, and solve problems in novel, non-verbal situations**. It represents the purest measure of **fluid intelligence (Gf)**—the ability to think on your feet when confronted with unfamiliar problems.

In Carroll's framework, Inductive Reasoning is strongly saturated with:
- **Fluid Intelligence (Gf):** The capacity for novel problem-solving
- **General Intelligence (g):** The core information-processing efficiency that underlies all reasoning

Notably, Inductive Reasoning is relatively independent of:
- **Crystallized Intelligence (Gc):** Minimal reliance on vocabulary or cultural knowledge
- **Educational background:** Abstract patterns can be solved regardless of formal training
- **Language:** Non-verbal format reduces linguistic and cultural loading

This makes Inductive Reasoning the most "culture-fair" component of cognitive assessment, though no test is entirely culture-free.

### Cognitive Processes in Inductive Reasoning

**1. Pattern Recognition**
The fundamental process is detecting regularities in visual sequences:
- **Attribute changes:** Color, size, shape, orientation
- **Positional patterns:** Movement, rotation, reflection
- **Numerical progressions:** Quantities increasing, decreasing, alternating
- **Logical relationships:** Elements appearing, disappearing, combining

Pattern recognition is a basic cognitive capacity present in early childhood but showing wide individual differences in sophistication.

**2. Hypothesis Generation**
When confronted with an abstract pattern, strong reasoners:
- Generate candidate rules ("maybe it's alternating between two shapes")
- Test hypotheses against the evidence ("does this rule account for all elements?")
- Revise or abandon rules that fail
- Converge on the correct pattern

This process mirrors scientific reasoning and diagnostic problem-solving in professional contexts.

**3. Rule Induction**
Moving from specific examples to general principles is the essence of inductive reasoning:
- Observing specific instances (square, circle, triangle, square, circle...)
- Inducing the general rule (pattern repeats every three elements)
- Applying the rule to predict the next instance (triangle should come next)

**4. Mental Manipulation**
Many items require mentally transforming visual elements:
- **Rotation:** Imagining shapes rotated 90 degrees
- **Reflection:** Flipping elements across an axis
- **Decomposition:** Breaking complex patterns into constituent parts
- **Recombination:** Assembling elements into new configurations

These mental manipulations engage spatial working memory and visualization capacity.

**5. Systematic Search**
Faced with multiple possible patterns, effective reasoners:
- Search systematically rather than randomly
- Consider multiple dimensions (not just shape, but also size, position, color)
- Eliminate impossible options
- Triangulate the correct answer by testing multiple constraints

### Typical Verify Inductive Reasoning Items

**Sequence Completion:**
A series of abstract shapes follows a pattern. Candidates identify which shape comes next. For example:
- A circle, square, triangle, circle, square, ___ (answer: triangle)
- Shapes rotating 45 degrees clockwise with each step
- Elements alternating between solid and outlined

**Matrix Completion:**
A 3×3 grid contains shapes following row and column rules. The bottom-right cell is missing. Candidates must identify the pattern and select the shape that completes the matrix.

**Rule Discovery:**
Two sets of boxes are shown: "Set A" (following a rule) and "Set B" (not following the rule). Candidates must infer the rule and determine which additional boxes belong in Set A.

**Transformation Sequences:**
A shape undergoes a series of transformations. Candidates must identify the pattern of transformation and predict the next step.

### Why Inductive Reasoning Matters

Unlike Numerical and Verbal reasoning, which can be coached through familiarity with business charts and argument structures, Inductive Reasoning resists coaching. It measures **raw problem-solving capacity**—the ability to extract structure from novel situations without relying on learned knowledge.

This has profound workplace implications:

**Innovation and Creativity:**
Innovators see patterns others miss. They recognize analogies between disparate domains, identify underlying principles, and generate novel solutions. These capacities depend on the pattern recognition and rule induction measured by Inductive Reasoning.

**Systems Thinking:**
Understanding complex systems—organizational dynamics, technological architectures, market ecosystems—requires seeing how components relate, identifying feedback loops, and recognizing emergent patterns. This is fundamentally inductive reasoning.

**Adaptation to Change:**
When the environment shifts, previous knowledge becomes less relevant. Those with strong fluid intelligence can quickly figure out new rules, adapt strategies, and solve problems they've never encountered before.

**Technical Problem-Solving:**
Troubleshooting unfamiliar equipment failures, debugging novel software errors, or diagnosing unusual process issues all require inductive reasoning: observing symptoms, inferring underlying causes, and testing hypotheses.

**Strategic Foresight:**
Leaders must recognize patterns in market trends, competitor behavior, and organizational dynamics to anticipate future states. This pattern recognition is the essence of strategic thinking.

### The Flynn Effect and Fluid Intelligence

An interesting historical note: Inductive Reasoning shows the **Flynn Effect**—the observation that IQ scores have risen substantially over the past century. The largest gains have occurred specifically on fluid intelligence measures like Raven's Progressive Matrices (an inductive reasoning test).

This suggests that modern environments—with their emphasis on abstract problem-solving, technological complexity, and rapid change—increasingly demand and develop fluid intelligence. As work becomes less routine and more knowledge-based, inductive reasoning becomes ever more critical to occupational success.

---

## The Integration of Domains: How Numerical, Verbal, and Inductive Reasoning Relate

### Shared Variance: The Role of g

While the three reasoning domains are conceptually distinct, they share substantial common variance. Correlation matrices typically show:

- Numerical and Verbal: r ≈ 0.50-0.60
- Numerical and Inductive: r ≈ 0.55-0.65
- Verbal and Inductive: r ≈ 0.50-0.60

These moderate-to-strong correlations reflect the influence of g—the general cognitive capacity that pervades all domains. A person with high g will typically score above average on all three tests, though the exact pattern varies.

Factor analysis confirms this structure:
- **First-order factors:** Three domain-specific factors (Numerical, Verbal, Inductive)
- **Second-order factor:** A general ability factor (g) accounting for correlations among the first-order factors

This hierarchical structure validates Verify's design: assessing three domains provides richer information than a single global score, while the composite GMA score captures the general factor common to all three.

### Domain-Specific Variance: Specialized Abilities

The correlations are not perfect (r ≠ 1.0), indicating that each domain also measures something unique:

**Numerical Reasoning** uniquely taps:
- Quantitative facility (comfort with numbers)
- Mathematical reasoning
- Tolerance for detail-oriented calculation

**Verbal Reasoning** uniquely taps:
- Language comprehension
- Deductive logic
- Precision in linguistic thinking

**Inductive Reasoning** uniquely taps:
- Spatial visualization
- Novel problem-solving
- Pattern recognition independent of language or numbers

This domain-specific variance has practical implications. A candidate might show:
- **Flat profile:** Similar performance across all three domains (typical for those high or low in g)
- **Quantitative strength:** Higher Numerical and Inductive, lower Verbal (common in STEM professionals)
- **Verbal strength:** Higher Verbal, lower Numerical and Inductive (common in humanities backgrounds)
- **Fluid intelligence strength:** Highest Inductive, moderate Numerical and Verbal (indicates strong abstract reasoning but less developed crystallized knowledge)

### Interpreting Score Profiles

**When Scores Are Consistent:**
A candidate scoring at the 75th percentile on all three domains demonstrates strong general mental ability with no notable weaknesses. This pattern indicates they possess the cognitive capacity to handle complex work across diverse task demands.

**When Scores Diverge:**
A candidate scoring at the 85th percentile on Verbal but only 50th percentile on Numerical may excel in roles heavy on communication, policy analysis, and strategic thinking but struggle with quantitative analysis and financial modeling. Such profiles should inform job-person fit decisions.

**The Role of Job Analysis:**
Organizations should conduct job analyses to determine:
- Is g most predictive (suggesting Verify G+ composite score is key)?
- Does one domain show incremental validity beyond g (suggesting domain-specific test)?
- Are certain ability patterns particularly well-suited to the role?

### The Verify G+ Combined Test Structure

Recall that Verify G+ presents **10 items from each domain, shuffled together** rather than blocked by type. This design choice reflects the hierarchical structure:

**Why Shuffle?**
- Prevents strategy shifts (candidates can't adopt a "math mindset" for a numerical block)
- Better reflects real-world cognitive demands (jobs don't segregate tasks by reasoning type)
- Assesses cognitive flexibility (switching between verbal, numerical, and abstract tasks)
- Produces a purer measure of g (by forcing integration across domains)

**Scoring:**
- **Composite GMA score:** Based on all 30 items, estimates g
- **Domain subscores:** Based on the 10 items per domain, estimate domain-specific abilities
- **Normative comparison:** Scores compared to relevant reference groups

This dual-level scoring provides both breadth (overall cognitive ability) and depth (domain-specific strengths/weaknesses).

---

## Key Takeaways

1. **Hierarchical Structure:** Intelligence is best understood as hierarchical, with the g factor at the apex, broad abilities (Stratum II) in the middle, and narrow abilities (Stratum III) at the base

2. **Carroll's Three-Stratum Theory:** This comprehensive framework, synthesizing 460+ studies, provides the definitive model of cognitive ability structure and directly informs Verify's design

3. **g Factor Primacy:** General Mental Ability is among the strongest predictors of job performance (validities 0.30-0.60), especially for complex jobs, because it enables learning, problem-solving, and adaptation

4. **Numerical Reasoning:** Assesses quantitative reasoning through interpretation of business data, engaging working memory, logical inference, and attention to detail—critical for data-driven decision-making

5. **True/False/Cannot Say Logic:** Verbal reasoning requires disciplined deductive thinking, distinguishing logical entailment from probable inference—a capacity essential for policy interpretation and critical thinking

6. **Inductive Reasoning as Fluid Intelligence:** Abstract pattern recognition provides the purest measure of novel problem-solving capacity, relatively independent of education and culture—essential for innovation and adaptation

7. **Shared Variance:** The three domains correlate moderately (r ≈ 0.50-0.65), reflecting their common dependence on g, validating the Verify G+ composite score as a measure of general mental ability

8. **Domain-Specific Variance:** Each domain also captures unique variance, enabling identification of cognitive strength profiles that inform job-person fit decisions

9. **Workplace Relevance:** Each domain predicts performance in specific contexts (Numerical: finance/analytics; Verbal: policy/strategy; Inductive: innovation/systems thinking)

10. **Verify G+ Design:** The shuffled 10+10+10 structure reflects hierarchical theory, measuring both g (composite) and domain-specific abilities (subscores), providing comprehensive cognitive assessment

---

## Chapter Navigation

[← Previous: Chapter 10 - Verify Suite Overview](/psychometric-guide/chapters/10-verify-overview/)

[Next: Chapter 12 - IRT Implementation in Verify →](/psychometric-guide/chapters/12-irt-verify/)

[↑ Back to Home](/psychometric-guide/)
